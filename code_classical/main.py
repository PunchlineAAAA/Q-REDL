import os
import logging
import torch
from seml.utils import flatten
import wandb
import json
import numpy as np
from collections import OrderedDict
import pandas as pd
from pathlib import Path
import itertools
import random
from pprint import pprint

from train import train
from dataset import get_dataset

from models.model_loader import load_model
from models.ModifiedEvidentialN import ModifiedEvidentialNet

from utils.io_utils import DataWriter
from utils.metrics import (
    accuracy,
    confidence,
    anomaly_detection,
    our_confidence,
    our_anomaly_detection,
)
from utils.metrics import compute_X_Y_alpha, name2abbrv

# åˆ›å»ºæ¨¡å‹çš„å­—å…¸ï¼Œé”®ä¸ºæ¨¡å‹ç±»å‹ï¼Œå€¼ä¸ºæ¨¡å‹ç±»
create_model = {"menet": ModifiedEvidentialNet}
# è®¾ç½®æ—¥å¿—çº§åˆ«ä¸ºINFO
logging.getLogger().setLevel(logging.INFO)


def main(config_dict):
    """ä¸»å‡½æ•°ï¼Œè´Ÿè´£æ•´ä¸ªè®­ç»ƒå’Œè¯„ä¼°æµç¨‹"""
    print("âœ… main() å·²å¯åŠ¨ï¼Œå‡†å¤‡è¯»å–é…ç½®å¹¶è®¾ç½®ç¯å¢ƒ")
    # ä»é…ç½®å­—å…¸ä¸­æå–å„ç§é…ç½®å‚æ•°
    config_id = config_dict["config_id"]  # é…ç½®ID
    suffix = config_dict["suffix"]  # åç¼€å

    seeds = config_dict["seeds"]  # éšæœºç§å­åˆ—è¡¨

    dataset_name = config_dict["dataset_name"]  # æ•°æ®é›†åç§°
    ood_dataset_names = config_dict["ood_dataset_names"]  # åˆ†å¸ƒå¤–(OOD)æ•°æ®é›†åç§°
    split = config_dict["split"]  # æ•°æ®é›†åˆ’åˆ†æ–¹å¼

    # æ¨¡å‹å‚æ•°
    model_type = config_dict["model_type"]  # æ¨¡å‹ç±»å‹
    name_model_list = config_dict["name_model"]  # æ¨¡å‹åç§°åˆ—è¡¨

    # æ¶æ„å‚æ•°
    directory_model = config_dict["directory_model"]  # æ¨¡å‹ç›®å½•
    architecture = config_dict["architecture"]  # æ¶æ„ç±»å‹
    input_dims = config_dict["input_dims"]  # è¾“å…¥ç»´åº¦
    output_dim = config_dict["output_dim"]  # è¾“å‡ºç»´åº¦
    hidden_dims = config_dict["hidden_dims"]  # éšè—å±‚ç»´åº¦
    kernel_dim = config_dict["kernel_dim"]  # æ ¸ç»´åº¦
    k_lipschitz = config_dict["k_lipschitz"]  # Lipschitzå¸¸æ•°

    # è®­ç»ƒå‚æ•°
    max_epochs = config_dict["max_epochs"]  # æœ€å¤§è®­ç»ƒè½®æ•°
    patience = config_dict["patience"]  # æ—©åœçš„è€å¿ƒå€¼
    frequency = config_dict["frequency"]  # è¯„ä¼°é¢‘ç‡
    batch_size = config_dict["batch_size"]  # æ‰¹æ¬¡å¤§å°
    lr_list = config_dict["lr"]  # å­¦ä¹ ç‡åˆ—è¡¨
    loss = config_dict["loss"]  # æŸå¤±å‡½æ•°ç±»å‹
    lamb1_list = config_dict["lamb1_list"]  # æ­£åˆ™åŒ–å‚æ•°Î»1åˆ—è¡¨
    lamb2_list = config_dict["lamb2_list"]  # æ­£åˆ™åŒ–å‚æ•°Î»2åˆ—è¡¨

    # åˆ†ç±»å™¨ç±»å‹å’ŒFisherçº¦æŸå‚æ•°
    clf_type = config_dict["clf_type"]
    fisher_c_list = config_dict["fisher_c"]
    noise_epsilon = config_dict["noise_epsilon"]  # å™ªå£°å¼ºåº¦

    # ç›®å½•å’Œå­˜å‚¨è®¾ç½®
    model_dir = config_dict["model_dir"]  # æ¨¡å‹ä¿å­˜ç›®å½•
    results_dir = config_dict["results_dir"]  # ç»“æœä¿å­˜ç›®å½•
    stat_dir = config_dict["stat_dir"]  # ç»Ÿè®¡æ•°æ®ä¿å­˜ç›®å½•
    store_results = config_dict["store_results"]  # æ˜¯å¦ä¿å­˜ç»“æœ
    store_stat = config_dict["store_stat"]  # æ˜¯å¦ä¿å­˜ç»Ÿè®¡æ•°æ®

    use_wandb = config_dict["use_wandb"]  # æ˜¯å¦ä½¿ç”¨Weights & Biasesè¿›è¡Œå®éªŒè·Ÿè¸ª

    # è®¾ç½®è®¾å¤‡(GPUæˆ–CPU)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    print("âœ… å¼€å§‹éå†è¶…å‚æ•°ç»„åˆ")
    # éå†æ‰€æœ‰çš„å‚æ•°ç»„åˆ
    for setting in itertools.product(
        seeds, lr_list, fisher_c_list, name_model_list, lamb1_list, lamb2_list
    ):
        (seed, lr, fisher_c, name_model, lamb1, lamb2) = setting

        print(f"ğŸ¯ å½“å‰ setting: seed={seed}, lr={lr}, fisher_c={fisher_c}, lamb1={lamb1}, lamb2={lamb2}")

        # è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿å¯é‡å¤æ€§
        random.seed(seed)
        os.environ["PYTHONHASHSEED"] = str(seed)
        np.random.seed(seed)
        torch.manual_seed(seed)
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
        torch.backends.cudnn.benchmark = False
        torch.backends.cudnn.deterministic = True

        ## åŠ è½½æ•°æ®é›†
        train_loader, val_loader, test_loader, N, output_dim = get_dataset(
            dataset_name, batch_size=batch_size, split=split, seed=seed
        )

        print("âœ… æ•°æ®é›†åŠ è½½å®Œæˆ")

        # è®°å½•é…ç½®ä¿¡æ¯
        logging.info(f"Received the following configuration: seed {seed}")
        logging.info(
            f"DATASET | "
            f"dataset_name {dataset_name} - "
            f"ood_dataset_names {ood_dataset_names} - "
            f"split {split}"
        )

        ## è®­ç»ƒæˆ–åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        if name_model is not None:
            # å¦‚æœæŒ‡å®šäº†æ¨¡å‹åç§°ï¼Œåˆ™åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
            logging.info(f"MODEL: {name_model}")
            config_dict = OrderedDict(
                name_model=name_model,
                model_type=model_type,
                seed=seed,
                dataset_name=dataset_name,
                split=split,
                loss=loss,
                epsilon=noise_epsilon,
            )

            if use_wandb:
                # åˆå§‹åŒ–Weights & Biasesè¿è¡Œ
                run = wandb.init(
                    project="IEDL",
                    reinit=True,
                    group=f"{dataset_name}_{ood_dataset_names}",
                    name=f"{model_type}_{loss}_ep{noise_epsilon}_{seed}",
                )

            # åŠ è½½æ¨¡å‹
            model = load_model(
                directory_model=directory_model,
                name_model=name_model,
                model_type=model_type,
            )
            stat_dir = stat_dir + f"{name_model}"

        else:
            # ä»å¤´å¼€å§‹è®­ç»ƒæ–°æ¨¡å‹
            logging.info(
                f"ARCHITECTURE | "
                f" model_type {model_type} - "
                f" architecture {architecture} - "
                f" input_dims {input_dims} - "
                f" output_dim {output_dim} - "
                f" hidden_dims {hidden_dims} - "
                f" kernel_dim {kernel_dim} - "
                f" k_lipschitz {k_lipschitz}"
            )
            logging.info(
                f"TRAINING | "
                f" max_epochs {max_epochs} - "
                f" patience {patience} - "
                f" frequency {frequency} - "
                f" batch_size {batch_size} - "
                f" lr {lr} - "
                f" loss {loss}"
            )
            logging.info(
                f"MODEL PARAMETERS | "
                f" clf_type {clf_type} - "
                f" fisher_c {fisher_c} - "
                f" lamb1 {lamb1} -"
                f" lamb2 {lamb2}"
            )

            # åˆ›å»ºé…ç½®å­—å…¸
            config_dict = OrderedDict(
                model_type=model_type,
                seed=seed,
                dataset_name=dataset_name,
                split=split,
                architecture=architecture,
                input_dims=input_dims,
                output_dim=output_dim,
                hidden_dims=hidden_dims,
                kernel_dim=kernel_dim,
                k_lipschitz=k_lipschitz,
                max_epochs=max_epochs,
                patience=patience,
                frequency=frequency,
                batch_size=batch_size,
                clf_type=clf_type,
                lr=lr,
                loss=loss,
                fisher_c=fisher_c,
                lamb1=lamb1,
                lamb2=lamb2,
            )

            if use_wandb:
                # åˆå§‹åŒ–Weights & Biasesè¿è¡Œ
                run = wandb.init(
                    project="IEDL",
                    reinit=True,
                    group=f"{__file__}_{dataset_name}_{architecture}_{suffix}",
                    name=f"{model_type}_{seed}_{loss}_lr{lr}_f{fisher_c}_{clf_type}",
                )
                wandb.config.update(config_dict)

            # ç­›é€‰æ¨¡å‹åˆ›å»ºæ‰€éœ€çš„å‚æ•°
            filtered_config_dict = {
                "seed": seed,
                "architecture": architecture,
                "input_dims": input_dims,
                "output_dim": output_dim,
                "hidden_dims": hidden_dims,
                "kernel_dim": kernel_dim,
                "k_lipschitz": k_lipschitz,
                "batch_size": batch_size,
                "lr": lr,
                "loss": loss,
                "clf_type": clf_type,
                "fisher_c": fisher_c,
                "lamb1": lamb1,
                "lamb2": lamb2,
            }

            # åˆ›å»ºæ¨¡å‹
            model = create_model[model_type](**filtered_config_dict)
            print("âœ… æ¨¡å‹å·²æ„å»ºå®Œæˆ")

            if torch.cuda.is_available():
                # å¦‚æœæœ‰å¤šä¸ªGPUï¼Œä½¿ç”¨DataParallel
                device_count = torch.cuda.device_count()
                if device_count > 1:
                    print(
                        f"Multiple GPUs detected (n_gpus={device_count}), use all of them!"
                    )
                    model = torch.nn.DataParallel(model)
                    model = model.module

            # ç”Ÿæˆå®Œæ•´çš„é…ç½®åç§°
            full_config_name = ""
            for k, v in config_dict.items():
                if isinstance(v, dict):
                    v = flatten(v)
                    v = [str(val) for key, val in v.items()]
                    v = "-".join(v)
                if k != "name_model":
                    full_config_name += str(v) + "-"
            full_config_name = full_config_name[:-1]

            # è®¾ç½®æ¨¡å‹ä¿å­˜è·¯å¾„
            model_path = model_dir + f"{seed}"
            stat_dir = stat_dir + f"model-{full_config_name}"

            Path(model_dir).mkdir(parents=True, exist_ok=True)

            # å°†æ¨¡å‹ç§»è‡³è®¾å¤‡å¹¶å¼€å§‹è®­ç»ƒ
            model.to(device)
            print("ğŸš€ å‡†å¤‡å¼€å§‹è®­ç»ƒ")    
            train(
                model,
                train_loader,
                val_loader,
                max_epochs=max_epochs,
                frequency=frequency,
                patience=patience,
                model_path=model_path,
                full_config_dict=config_dict,
                use_wandb=use_wandb,
                device=device,
                output_dim=output_dim,
            )

            # åŠ è½½æœ€ä½³æ¨¡å‹
            model.load_state_dict(torch.load(model_path + "_best")["model_state_dict"])
            print("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œæœ€ä½³æ¨¡å‹å·²åŠ è½½")

        ## æµ‹è¯•æ¨¡å‹
        model.to(device)
        print("ğŸ” æ­£åœ¨è¿›è¡Œæµ‹è¯•é›†è¯„ä¼°")
        model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼

        with torch.no_grad():
            # è®¡ç®—æµ‹è¯•é›†ä¸Šçš„é¢„æµ‹ç»“æœ
            id_Y_all, id_X_all, id_alpha_pred_all = compute_X_Y_alpha(
                model, test_loader, device
            )

            # ä¿å­˜æŒ‡æ ‡
            metrics = {}
            scores = {}
            ood_scores = {}
            # è®¡ç®—åˆ†å¸ƒå†…æ•°æ®çš„å‡†ç¡®ç‡
            metrics["id_accuracy"] = accuracy(
                Y=id_Y_all, alpha=id_alpha_pred_all
            ).tolist()

            # è®¡ç®—å„ç§ä¸ç¡®å®šæ€§åº¦é‡æŒ‡æ ‡
            for name in [
                "max_prob",
                "max_modified_prob",
                "max_alpha",
                "alpha0",
                "differential_entropy",
                "mutual_information",
            ]:
                # æ ¹æ®æ¨¡å‹ç±»å‹è·³è¿‡æŸäº›æŒ‡æ ‡
                if model_type == "duq" and name != "max_alpha":
                    continue
                if name == "max_modified_prob" and model_type != "menet":
                    continue

                abb_name = name2abbrv[name]  # è·å–ç¼©å†™åç§°
                save_path = None
                if store_stat:
                    save_path = f"{stat_dir}/{config_id}_id_{abb_name}.csv"
                    Path(stat_dir).mkdir(parents=True, exist_ok=True)

                # æ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©é€‚å½“çš„ç½®ä¿¡åº¦è®¡ç®—æ–¹æ³•
                if model_type == "evnet" or model_type == "duq":
                    aupr, auroc, score = confidence(
                        Y=id_Y_all,
                        alpha=id_alpha_pred_all,
                        uncertainty_type=name,
                        save_path=save_path,
                        return_scores=True,
                    )
                elif model_type == "menet" or model_type == "ablation":
                    aupr, auroc, score = our_confidence(
                        Y=id_Y_all,
                        alpha=id_alpha_pred_all,
                        uncertainty_type=name,
                        save_path=save_path,
                        return_scores=True,
                    )
                else:
                    raise NotImplementedError

                # ä¿å­˜AUPRå’ŒAUROCæŒ‡æ ‡
                metrics[f"id_{abb_name}_apr"], metrics[f"id_{abb_name}_auroc"] = (
                    aupr,
                    auroc,
                )
                scores[f"{abb_name}"] = score

            # å¤„ç†åˆ†å¸ƒå¤–(OOD)æ•°æ®é›†
            ood_dataset_loaders = {}
            for ood_dataset_name in ood_dataset_names:
                print(f"ğŸ” æ­£åœ¨å¤„ç† OOD æ•°æ®é›†: {ood_dataset_name}")
                config_dict["ood_dataset_name"] = ood_dataset_name
                # åŠ è½½OODæ•°æ®é›†
                _, _, ood_test_loader, _, _ = get_dataset(
                    ood_dataset_name, batch_size=batch_size, split=split, seed=seed
                )
                ood_dataset_loaders[ood_dataset_name] = ood_test_loader

                # è®¡ç®—OODæ•°æ®çš„é¢„æµ‹ç»“æœ
                ood_Y_all, ood_X_all, ood_alpha_pred_all = compute_X_Y_alpha(
                    model, ood_test_loader, device, noise_epsilon=noise_epsilon
                )

                # å¦‚æœæ˜¯åœ¨åŸå§‹æ•°æ®é›†ä¸Šæ·»åŠ å™ªå£°ï¼Œè®¡ç®—å‡†ç¡®ç‡
                if ood_dataset_name == dataset_name and noise_epsilon != 0:
                    metrics["ood_accuracy"] = accuracy(
                        Y=ood_Y_all, alpha=ood_alpha_pred_all
                    ).tolist()

                # è®¡ç®—OODæ£€æµ‹æŒ‡æ ‡
                for name in [
                    "max_prob",
                    "max_modified_prob",
                    "max_alpha",
                    "alpha0",
                    "differential_entropy",
                    "mutual_information",
                ]:
                    if model_type == "duq" and name != "max_alpha":
                        continue
                    if name == "max_modified_prob" and model_type != "menet":
                        continue

                    abb_name = name2abbrv[name]
                    save_path = None
                    if store_stat:
                        save_path = f"{stat_dir}/{config_id}_ood_{abb_name}.csv"

                    # æ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©é€‚å½“çš„å¼‚å¸¸æ£€æµ‹æ–¹æ³•
                    if model_type == "evnet" or model_type == "duq":
                        aupr, auroc, _, ood_score = anomaly_detection(
                            alpha=id_alpha_pred_all,
                            ood_alpha=ood_alpha_pred_all,
                            uncertainty_type=name,
                            save_path=save_path,
                            return_scores=True,
                        )
                    elif model_type == "menet" or model_type == "ablation":
                        aupr, auroc, _, ood_score = our_anomaly_detection(
                            alpha=id_alpha_pred_all,
                            ood_alpha=ood_alpha_pred_all,
                            uncertainty_type=name,
                            save_path=save_path,
                            return_scores=True,
                        )
                    else:
                        raise NotImplementedError

                    metrics[f"ood_{abb_name}_apr"], metrics[f"ood_{abb_name}_auroc"] = (
                        aupr,
                        auroc,
                    )
                    ood_scores[f"{abb_name}"] = ood_score

                # æ‰“å°æŒ‡æ ‡
                print("Metrics: ")
                pprint(metrics)

                # è®°å½•åˆ°Weights & Biases
                if use_wandb:
                    data_df = pd.DataFrame(data=[metrics])
                    wandb_table = wandb.Table(dataframe=data_df)
                    wandb.log({"{}".format(ood_dataset_name): wandb_table})

                # ä¿å­˜ç»“æœåˆ°CSVæ–‡ä»¶
                if store_results:
                    row_dict = config_dict.copy()
                    for k, v in config_dict.items():
                        if isinstance(v, list):
                            row_dict[k] = str(v)

                    row_dict.update(metrics)  # æµ…æ‹·è´

                    Path(results_dir).mkdir(parents=True, exist_ok=True)
                    data_writer = DataWriter(dump_period=1)
                    csv_file = f"{results_dir}/{config_id}.csv"
                    data_writer.add(row_dict, csv_file)

        # ç»“æŸWeights & Biasesè¿è¡Œ
        if use_wandb:
            run.finish()

    return


if __name__ == "__main__":
    # æ˜¯å¦ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°
    use_argparse = True

    if use_argparse:
        # è§£æå‘½ä»¤è¡Œå‚æ•°
        import argparse

        my_parser = argparse.ArgumentParser()
        my_parser.add_argument("--configid", action="store", type=str, required=True)
        my_parser.add_argument("--suffix", type=str, default="debug", required=False)
        args = my_parser.parse_args()
        args_configid = args.configid
        args_suffix = args.suffix
    else:
        # ä½¿ç”¨é»˜è®¤å€¼
        args_configid = "test"
        args_suffix = "debug"

    # å¤„ç†é…ç½®IDè·¯å¾„
    if "/" in args_configid:
        args_configid_split = args_configid.split("/")
        my_config_id = args_configid_split[-1]
        config_tree = "/".join(args_configid_split[:-1])
    else:
        my_config_id = args_configid
        config_tree = ""

    # è®¾ç½®é¡¹ç›®è·¯å¾„å’Œé…ç½®æ–‡ä»¶è·¯å¾„
    PROJPATH = os.getcwd()
    cfg_dir = f"{PROJPATH}/configs"
    os.makedirs(cfg_dir, exist_ok=True)
    cfg_path = f"{PROJPATH}/configs/{config_tree}/{my_config_id}.json"
    logging.info(f"Reading Configuration from {cfg_path}")

    # è¯»å–é…ç½®æ–‡ä»¶
    with open(cfg_path) as f:
        proced_config_dict = json.load(f)

    # æ·»åŠ é¢å¤–çš„é…ç½®å‚æ•°
    proced_config_dict["config_id"] = my_config_id
    proced_config_dict["suffix"] = args_suffix

    # è®¾ç½®ä¿å­˜è·¯å¾„
    proced_config_dict["model_dir"] = f"{PROJPATH}/saved_models/{my_config_id}/"
    proced_config_dict["results_dir"] = f"{PROJPATH}/saved_models/{my_config_id}/"
    proced_config_dict["stat_dir"] = f"{PROJPATH}/results/{config_tree}_stat/"

    # è¿è¡Œä¸»å‡½æ•°
    main(proced_config_dict)